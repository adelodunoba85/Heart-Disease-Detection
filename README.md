# Interpretable Clinical Machine Learning for Heart Disease Prediction
Overview

This repository implements predictive modelling and explainability techniques for heart disease detection using structured clinical data.

The study evaluates tree-based and ensemble models and applies post-hoc interpretability methods including SHAP, LIME, and counterfactual explanations.

## Dataset

Heart Disease dataset from the UCI Machine Learning Repository.

303 patients

13 clinical features

Binary outcome (presence of heart disease)

## Methods

Models Evaluated

Decision Tree

AdaBoost

Gaussian Naive Bayes

## Evaluation Metrics

Accuracy

Precision

Recall

F1-score

ROC-AUC

Log Loss

## Explainability Techniques

LIME (Local Interpretable Model-Agnostic Explanations)

SHAP (SHapley Additive exPlanations)

DiCE (Counterfactual explanations)

## Key Results

Best model accuracy: ~80%

ROC-AUC: ~0.80

Counterfactual explanations generated for individual patient risk modification

## Research Contribution

Demonstrates integration of predictive modelling and explainability techniques for clinical decision support systems.
